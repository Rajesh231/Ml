{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1EACGaODn2i7ibsKWl3Dtk7M6dYrOq982",
      "authorship_tag": "ABX9TyOsEV9DOmLhmkdb4xmn5QxO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rajesh231/Ml/blob/master/BotnetDetection_CNN_HighAccNdLowLoss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkeqwcSxGO9k",
        "colab_type": "text"
      },
      "source": [
        "Botnet Detection using CTU-13 dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-8kVtJWEipR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pyyaml h5py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0V1p-vFGdqT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf \n",
        "from tensorflow.keras import Sequential \n",
        "from tensorflow.keras.callbacks import EarlyStopping \n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCitKKNTU2DV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Conv1D, MaxPool1D,Flatten,Dense,Dropout,BatchNormalization \n",
        "print(tf.__version__) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRG9UV0jVZ_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import seaborn as sns \n",
        "import matplotlib.pyplot as plt \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oqosz9c9VmqT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.preprocessing import StandardScaler \n",
        "from sklearn.feature_selection import variance_threshold "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYENo6-LooQs",
        "colab_type": "text"
      },
      "source": [
        "**Reading the CSV file from Mounted Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUr89TCUrWgZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/finalpreprocessed2.csv\") \n",
        "df.head() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5buOy-qxX9q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0rfvclvo3XC",
        "colab_type": "text"
      },
      "source": [
        "**Preprocessing of the data which left after preprocessing in MS Excel**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuPORuStxkq0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df.drop(labels =['Label','State'],axis =1) \n",
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gTOisfSxpCJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = df['Label'] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZ4xyBlgxr2Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#stratified shuffling is done to divide the data in equal ration on the basis of parameter label\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state = 0, stratify =y) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hpALnHHxvef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndFaWp8sxzCF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test.shape "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_HwTNxFx2Ly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_selection import VarianceThreshold \n",
        "filter = VarianceThreshold(0.01) \n",
        "X_train = filter.fit_transform(X_train) \n",
        "X_test = filter.transform(X_test) \n",
        "X_train.shape, X_test.shape "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnzOuSu5yUjU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_T = X_train.T\n",
        "X_test_T = X_test.T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o29Dusi3ybyW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_T = pd.DataFrame(X_train_T)\n",
        "X_test_T = pd.DataFrame(X_test_T)\n",
        "X_test_T.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdSpdjQ_yfyO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_T.duplicated().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXYVGNl7ykQd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "duplicated_features = X_train_T.duplicated()\n",
        "duplicated_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsAhTVQQyuH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_to_keep = [not index for index in duplicated_features]\n",
        "features_to_keep"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXJTn8Qpyufk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train_T[features_to_keep].T\n",
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSRSUtGeyutk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = X_test_T[features_to_keep].T\n",
        "X_test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DE0W_lz2zZ3s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "X_train "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CA3awyD0MOV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0XicbSy0Mj_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train.shape,X_test.shape "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoRy_5jg4TvT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(830608,7,1) \n",
        "X_test = X_test.reshape(207653,7,1) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CukpNUvp0Mnd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test.shape,X_train.shape "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1924sBY10MhH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#as y is a series so y_train and y_test are also series therefore we need to convert them to a numpy array.\n",
        "y_train = y_train.to_numpy() \n",
        "y_test = y_test.to_numpy() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btuvodT3ybZs",
        "colab_type": "text"
      },
      "source": [
        "**Model buildin process starts from here. I will build this model using Convolutional Neural Networks**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9Lxp-GH15-B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import MaxPool1D\n",
        "from keras.models import load_model\n",
        "model = Sequential()\n",
        "model.add(Conv1D(64,3,activation='relu',input_shape=(7,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool1D(pool_size =2))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv1D(128,3,activation='relu',input_shape=(7,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool1D(2))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv1D(128,3,activation='relu',input_shape=(7,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool1D(2))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv1D(256,3,activation='relu',input_shape=(7,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool1D(2))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(1,activation = 'sigmoid'))\n",
        "#model.add(EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='min', baseline=None, restore_best_weights=True))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JetHfPVY16Df",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXXrqlr2OhkA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compile the model\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "#model.compile(optimizer=SGD(lr=0.000005),loss =\"binary_crossentropy\",metrics = ['f1_score'])\n",
        "model.compile(optimizer=SGD(lr=0.01), loss='binary_crossentropy', metrics=['accuracy']) \n",
        "\n",
        "#simple early stopping and model chekcpoint functions\n",
        "es = EarlyStopping(monitor='val_loss',mode = 'min',verbose =1,patience = 10)\n",
        "mc = ModelCheckpoint('best_model.h5',monitor = 'val_loss', mode = 'min', verbose =1, save_best_only = True)\n",
        "lr = ReduceLROnPlateau(monitor = \"val_loss\", factor = 0.1, patience = 4, verbose = 0, mode = \"auto\", min_delta= 1e-04, cooldown = 0,min_lr = 0)\n",
        "# fit the model\n",
        "#history = model.fit(Xtrain, ytrain, validation_split=0.3, epochs=10, verbose=0)\n",
        "\n",
        "# evaluate the model\n",
        "#loss, accuracy, f1_score, precision, recall = model.evaluate(Xtest, ytest, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll6so_S1152T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(X_train,y_train,epochs = 225,validation_split=0.25 ,verbose =1,callbacks=[es,mc,lr])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oumFcqZmKDZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Recreate the exact same model, including its weights and the optimizer by loading our saved model.\n",
        "model = tf.keras.models.load_model('best_model.h5')\n",
        "\n",
        "# Show the model architecture\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yA4RjUOoz_v7",
        "colab_type": "text"
      },
      "source": [
        "**Evaluating the loaded or saved model to have a glance over training accuracy, training loss and testing accuracy, testing loss**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u87UkDGGDXu4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#evaluating the model \n",
        "trainloss,trainacc = model.evaluate(X_train,y_train,verbose=0)\n",
        "testloss,testacc = model.evaluate(X_test,y_test,verbose=0)\n",
        "print('train: %.3f, %.3f, Test: % .3f, %.3f'%(trainacc,trainloss,testacc,testloss))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejyaPR45aHqi",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIy39CeOAwsQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " y_predict = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqGDVeucA3F6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_predict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dduIJC5Q15yr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history.history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYcp6LB3IUqM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(history.history['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYP8vb5h15wK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_learningCurve(history,epoch):\n",
        "  #ploting training & validation accuracy values\n",
        "  epoch_range = range(1,epoch+1)\n",
        "  plt.plot(epoch_range,history.history['accuracy'])\n",
        "  plt.plot(epoch_range,history.history['val_accuracy'])\n",
        "  plt.title('Model accuracy')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Train','test'],loc='right')\n",
        "  plt.show()\n",
        "\n",
        "#plot training & validation loss values\n",
        "  plt.plot(epoch_range,history.history['loss'])\n",
        "  plt.plot(epoch_range,history.history['val_loss'])\n",
        "  plt.title('Model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Train','test'],loc='right')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5y7QAoOz15pY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_learningCurve(history,49)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaBfR2pW5jTr",
        "colab_type": "text"
      },
      "source": [
        "**By looking at the above learning curves we can say that our model is neither underfitting nor overfitting as the curves for both training and testing data are nearly same. If model was underfitting then these two curves would have huge variation and if model was overfitting then these two curves may be moving in opposite direction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OMRFR0w5hvP",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iljwpUjw6euN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_predict = np.asarray(y_predict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcGG_05Y51sd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "conff = confusion_matrix(y_test,y_predict.round())\n",
        "conff"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAFrKF0p6Sgg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#Plotting Confusion matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "classes = [0,1]\n",
        "plt.imshow(conff,interpolation='nearest',cmap=plt.cm.Greens)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(len(classes))\n",
        "plt.xticks(tick_marks,classes)\n",
        "plt.yticks(tick_marks,classes)\n",
        "accuracy = max(history.history['accuracy'])\n",
        "misclass =1-max(history.history['accuracy'])\n",
        "fmt ='d'\n",
        "thresh = conff.max()/2\n",
        "for i, j in itertools.product(range(conff.shape[0]),range(conff.shape[1])):\n",
        "  plt.text(j,i,format(conff[i,j],fmt),horizontalalignment='center', color=\"white\" if conff[i,j]>thresh else \"black\")\n",
        "  plt.tight_layout()\n",
        "  plt.ylabel('True label')\n",
        "  #plt.xlabel('Predicted label')\n",
        "  plt.xlabel('Predicted label ( 1-True,0-False )\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmZBZkBj9nuU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TP = true_positives = 4341\n",
        "TN = true_negatives = 201790\n",
        "FP = false_positives = 1051\n",
        "FN = false_negatives = 471"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvRHcUGw9n4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results={}\n",
        "metric = \"Accuracy\"\n",
        "results[metric]=(TP+TN)/(TP+TN+FP+FN)\n",
        "print(f\"{metric} is {results[metric]: .4f}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5B1iD4829n8b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "metric = \"Recall\"\n",
        "results[metric]=TP/(TP+FN)\n",
        "print(f\"{metric} is {results[metric]: .4f}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQQg4niQ-hHh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "metric = \"Precision\"\n",
        "results[metric]=TP/(TP+FP)\n",
        "print(f\"{metric} is {results[metric]: .4f}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jxZRq7V-hLC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "metric = \"F1-Score\"\n",
        "results[metric]= 2/(1/results[\"Precision\"]+1/results[\"Recall\"])\n",
        "print(f\"{metric} is {results[metric]: .4f}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQr5i_utMFeO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Let's check various metrics using sklearns inbuitl function to compare the values our custom functions generated\n",
        "from sklearn import metrics\n",
        "print(f\"Actual accuracy_score : {metrics.accuracy_score(y_test,y_predict.round()): .6f}\")\n",
        "print(f\"Actual recall_score : {metrics.recall_score(y_test,y_predict.round()): .4f}\")\n",
        "print(f\"Actual precision_score : {metrics.precision_score(y_test,y_predict.round()): .4f}\")\n",
        "print(f\"Actual f1_score : {metrics.f1_score(y_test,y_predict.round()): .4f}\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}